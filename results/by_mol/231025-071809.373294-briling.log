namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-subset4xtb-noH-ns64-nv48-d48-layers3-energy-mlp-both-rxnmapper', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=True, random_baseline=False, two_layers_atom_diff=True, noH=True, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=0.0001)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo-subset4xtb/231005-222350.857040-briling.best_checkpoint.pt', CV=1, num_epochs=269, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=True, random_baseline=False, two_layers_atom_diff=True, noH=True, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=0.0001, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles_rxnmapper.xtb-subset.noH.v6a'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.2056

CV iter 1/1
Using random splits
total / train / test / val: 4774 4297 239 238
trainable params in model:  10383318
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo-subset4xtb/231005-222350.857040-briling.best_checkpoint.pt
num epochs: 269
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 0.0001
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.205589010570657
Statistics on val_best_checkpoint
mae: 2.2491758692008195
MSELoss: 0.10894711045548319
mean_pred: -0.008053835481405258
std_pred: 0.8371208230654399
mean_targets: -0.018896354362368584
std_targets: 0.936119427283605
Evaluating on test, with test size:  239
Statistics on test_split_1
mae: 2.170332837019334
MSELoss: 0.10924839582294225
mean_pred: -0.004575434140861034
std_pred: 0.9862648725509644
mean_targets: 0.03807484780748685
std_targets: 1.0444153835376104
>>> 1873 -0.804314 -0.64333314
>>> 3891 0.5844579 0.83218837
>>> 389 -0.7753813 -0.5395899
>>> 1734 -1.0032009 -0.96717167
>>> 3741 0.440619 0.7554251
>>> 762 -0.5636414 -0.45863497
>>> 3708 0.16183676 0.13252515
>>> 1406 -0.96252686 -1.2524375
>>> 2884 -1.0465598 -1.130088
>>> 329 -0.20168936 -0.94672906
>>> 2397 3.243885 3.7068377
>>> 4317 -1.0641034 -0.9842611
>>> 3753 0.048048876 -0.3304696
>>> 4118 -0.91082746 -0.8160156
>>> 34 -1.3283527 -1.3843516
>>> 3348 -0.63610536 -0.8779214
>>> 821 -1.0399052 -0.5013272
>>> 1438 1.1579788 1.2349467
>>> 287 0.5642161 0.6253951
>>> 2414 0.96883076 1.3000638
>>> 4731 1.4760131 1.4086089
>>> 3943 -0.4632675 -0.5410471
>>> 4413 -0.6153543 -0.9955946
>>> 2161 2.7869306 2.285106
>>> 2040 1.2396694 1.359704
>>> 1656 -2.092463 -1.7909472
>>> 4102 -0.9908664 -0.6348957
>>> 2989 -0.015770208 0.62546754
>>> 581 -0.76243174 -0.7129844
>>> 1104 -0.62488604 -0.45798528
>>> 2080 2.2162127 2.12462
>>> 2412 0.20095208 0.29434517
>>> 1439 1.7077768 1.1061221
>>> 1684 -0.21150896 -0.119527355
>>> 2240 1.0845501 1.1368986
>>> 1558 -1.0452496 -0.6659228
>>> 4277 2.5911071 1.9593868
>>> 4310 -0.23622583 -0.36114037
>>> 2533 -0.8236275 -0.3236011
>>> 1146 0.47433674 0.17905107
>>> 2856 -0.5063084 -0.5789539
>>> 416 -0.8424915 -0.87148315
>>> 3796 -0.49416366 -0.29142347
>>> 1602 -0.00540107 0.17960905
>>> 3356 0.28803214 0.5697984
>>> 3458 1.517466 1.7144974
>>> 2478 1.3284727 1.1674495
>>> 2495 0.3790082 0.32166547
>>> 3518 -0.5543066 -0.3759549
>>> 4589 1.201527 1.0262661
>>> 3866 -0.8928671 -0.19128917
>>> 60 -0.8041529 -0.8488084
>>> 2255 -0.55653214 -0.6803624
>>> 788 -0.6885363 -0.6789489
>>> 1118 -0.6767394 -0.81614614
>>> 1792 -0.24646327 -0.45691073
>>> 4104 -0.36181694 -0.49081594
>>> 713 1.3276731 1.1096505
>>> 3561 1.1067414 1.476469
>>> 4410 -1.4161736 -1.0310775
>>> 4372 0.93627024 0.9522303
>>> 3727 -0.1570477 -0.47961715
>>> 2301 -0.3885044 -0.22390094
>>> 4557 -1.1161851 -1.2199771
>>> 3881 3.6827636 2.3302584
>>> 936 -1.1071701 -1.2867168
>>> 455 -0.8120595 -0.7550274
>>> 538 0.874878 0.62604785
>>> 874 0.6014724 0.10770345
>>> 268 -0.8192963 -0.86533284
>>> 3815 -1.5794114 -1.5093673
>>> 545 -0.5305388 -0.76026547
>>> 2388 0.8287904 0.86833173
>>> 4701 1.1278222 2.2589283
>>> 1551 -0.24893416 -0.46382454
>>> 1258 -0.9594762 -0.9771416
>>> 413 -0.6315382 -0.7430175
>>> 4489 0.060007297 0.107316345
>>> 4011 -0.548491 -0.6274917
>>> 3556 0.2860971 -0.0670502
>>> 3527 -0.6803107 -0.5651941
>>> 93 -1.51474 -1.5276589
>>> 1524 -0.5053028 -0.5412008
>>> 1007 -0.8441268 -1.2377582
>>> 2359 0.16999826 -0.07626676
>>> 2023 0.09211625 0.087211624
>>> 2566 1.6088505 1.1267484
>>> 126 -1.0538303 -1.3532996
>>> 2201 -1.2115248 -1.3515315
>>> 443 1.5913395 1.1628231
>>> 4477 -0.6345279 -0.62853885
>>> 3132 0.02297899 -0.098518364
>>> 2578 2.163856 0.42774191
>>> 3095 0.8313305 0.8325779
>>> 3860 -0.99577105 -1.1004068
>>> 4321 -0.5251936 -0.63065666
>>> 3072 0.2771404 0.14750473
>>> 3656 1.0584921 1.0049003
>>> 1649 -1.1788175 -0.38550082
>>> 2483 -0.48046637 -0.034940735
>>> 2227 0.4091365 0.69503146
>>> 1647 -1.4550912 -1.5378727
>>> 434 -1.0769453 -0.9647126
>>> 508 0.71550345 0.64065903
>>> 4030 -0.9724724 -0.9790977
>>> 32 -1.0144738 -0.88861054
>>> 2378 1.2554752 1.1145605
>>> 2072 -0.29621848 -0.48785153
>>> 4295 -1.2732406 -1.65361
>>> 2880 -0.84800845 -0.9952952
>>> 3895 0.21886146 0.1387779
>>> 3367 -0.6830394 -0.49799836
>>> 2819 0.9916661 1.0367209
>>> 180 -0.6034696 -0.7439449
>>> 2871 -0.02298058 -0.6892961
>>> 1282 -0.13555674 0.04636041
>>> 4726 3.3202038 2.994051
>>> 2046 -0.3958796 -0.80446255
>>> 4360 -0.20757169 -0.32864672
>>> 2174 -0.8792157 -0.7997745
>>> 4391 -0.92508626 -1.0894275
>>> 719 0.05733386 0.08118233
>>> 3892 0.99644536 0.26546234
>>> 295 0.9211319 0.33641917
>>> 3963 0.2800864 0.2661868
>>> 794 -0.72247225 -0.8665585
>>> 3665 -1.074838 -0.60155284
>>> 4201 1.6159328 0.8213573
>>> 3143 0.051522993 0.3691024
>>> 3306 -0.6112049 -0.5822027
>>> 2395 -1.1038252 -0.580854
>>> 922 -0.41235054 -0.99440295
>>> 4007 0.023495713 -0.15458617
>>> 2467 -1.4061968 -1.3573903
>>> 2557 0.84699005 0.77533054
>>> 3121 -0.81999934 -0.57706994
>>> 1326 0.29189464 0.54581237
>>> 4542 2.3729944 1.6926159
>>> 3273 -1.0975051 -1.09677
>>> 915 -1.7742411 -1.4754492
>>> 1425 1.2771043 1.2714595
>>> 231 -0.001554758 -0.07670224
>>> 2778 -0.15709233 -0.47210222
>>> 1474 0.5618798 0.013800973
>>> 1221 0.4606435 0.39846292
>>> 2751 -0.4219523 0.01601406
>>> 2917 0.36709163 0.5850531
>>> 1100 -0.36901727 -0.48084337
>>> 1257 -0.40747365 -0.34058556
>>> 1888 0.41414487 0.9469847
>>> 1922 -0.011388625 -0.10352692
>>> 687 -0.6026876 -1.2141626
>>> 4610 -1.4597112 -1.5390391
>>> 2599 -0.7272424 -0.7945815
>>> 2795 -0.29068187 -0.2873675
>>> 4063 1.4626462 1.6430295
>>> 3092 1.1195902 1.0474418
>>> 4028 1.6125013 1.5256722
>>> 2625 1.2405812 1.4620461
>>> 89 0.5569525 0.43294507
>>> 2446 0.71012634 0.08543746
>>> 113 -1.1779362 -0.8880252
>>> 1235 -1.0765408 -1.1253133
>>> 3476 -0.1699354 -0.8481354
>>> 2936 -0.046598837 0.062138475
>>> 191 -1.0875645 -0.6460842
>>> 3839 -1.6475681 -1.7882913
>>> 2341 1.0695937 0.66164124
>>> 2945 -0.057609595 -0.17481744
>>> 16 -1.534198 -1.8664781
>>> 4576 3.9572244 3.9601655
>>> 3295 -0.20201539 -0.106846675
>>> 4344 0.8414983 0.73679817
>>> 3261 -0.38751996 -0.25602064
>>> 3463 0.50136656 0.024475835
>>> 1760 -0.41102144 -0.30260673
>>> 4166 -0.2991508 -0.8315045
>>> 2747 2.3169615 2.5460596
>>> 4254 -0.8023183 -0.606017
>>> 1557 -0.27081808 -0.6249992
>>> 2159 2.4671519 2.457404
>>> 1755 -0.2257704 -0.052396566
>>> 3178 0.34864894 0.20934129
>>> 1871 -0.7672431 -0.716393
>>> 1759 -0.46570793 -0.7740237
>>> 3486 0.5275994 0.14058806
>>> 1312 -0.6152286 -0.6548636
>>> 2425 -0.8782206 -0.5935311
>>> 2999 0.842043 0.33542022
>>> 4050 1.3270625 1.1612444
>>> 672 1.2893723 1.2713852
>>> 3310 -0.41426003 -0.18042965
>>> 4462 1.2846575 1.2360443
>>> 3034 -0.11991107 -0.6116099
>>> 1248 -0.5823968 -0.45878968
>>> 1794 -1.3655338 -1.3467556
>>> 2213 0.9052141 1.2407829
>>> 2654 0.5142607 0.026759986
>>> 1662 0.63029563 -0.003270071
>>> 1128 0.5356618 0.9208602
>>> 3200 1.197928 0.64585006
>>> 4747 -0.6134806 -0.51269454
>>> 3918 1.4647708 1.2426807
>>> 2289 -0.73930174 -0.69980305
>>> 845 0.22633392 0.34347898
>>> 3655 0.9034063 0.9937577
>>> 2010 -0.13900235 -0.12921146
>>> 3940 -0.7778068 -0.7177721
>>> 3078 0.36089557 0.39232388
>>> 4525 0.506575 0.36089006
>>> 1427 1.403242 1.6079111
>>> 2270 -0.07931965 0.0324604
>>> 1105 -0.6805163 -0.93808633
>>> 361 -0.16465278 -0.110156536
>>> 892 1.4800932 1.3509594
>>> 2574 -0.6513742 -0.6065611
>>> 1061 -0.42918256 -0.34762812
>>> 14 0.3766624 0.53894943
>>> 2666 -1.1571989 -0.66956574
>>> 1543 1.1789078 1.1852691
>>> 1378 -0.045034282 0.3458635
>>> 3622 1.7089394 1.399204
>>> 3539 -0.7119147 -0.79632485
>>> 3084 -0.56938964 -0.29592484
>>> 3230 0.86108834 0.79006875
>>> 464 0.7673291 0.34993356
>>> 3358 0.012351639 -0.07019462
>>> 4501 -1.6101024 -1.3100901
>>> 2490 0.80881894 0.7764338
>>> 609 -1.3579831 -1.1923119
>>> 2637 1.1453823 0.87019217
>>> 133 1.0549593 0.7899875
>>> 4097 -0.56959474 0.07127178
>>> 293 -1.3388032 -0.84880745
>>> 3101 0.62499917 0.54416466
>>> 3406 0.0786676 -0.0011566635
>>> 3573 0.38165322 0.23797761
>>> 3155 1.1103164 1.245965
>>> 881 -0.9533992 -1.1248119

Mean MAE across splits 2.170332837019334 +- 0.0
delta MAE: 2.29e-08
