namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-xtb-noH-ns64-nv48-d48-layers3-energy-mlp-both-crossattention', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention='cross', sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=1e-05)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo-xtb/231005-021130.204594-briling.best_checkpoint.pt', CV=1, num_epochs=95, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention='cross', sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=1e-05, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles_mapped.noH.xtb.v6'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.2056

CV iter 1/1
Using random splits
total / train / test / val: 4774 4297 239 238
trainable params in model:  10352166
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo-xtb/231005-021130.204594-briling.best_checkpoint.pt
num epochs: 95
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 1e-05
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.205589010570657
Statistics on val_best_checkpoint
mae: 3.0527659123963637
MSELoss: 0.2022102511798342
mean_pred: -0.029281836872299512
std_pred: 0.9056215584278107
mean_targets: -0.018896354362368584
std_targets: 0.936119427283605
Evaluating on test, with test size:  239
Statistics on test_split_1
mae: 2.859086183603462
MSELoss: 0.1843432458738486
mean_pred: 0.0065316134442885716
std_pred: 0.9771938582261404
mean_targets: 0.03807484780748685
std_targets: 1.0444153835376104
>>> 1873 -0.804314 -0.7732416
>>> 3891 0.5844579 0.6288724
>>> 389 -0.7753813 -0.84984416
>>> 1734 -1.0032009 -0.7449667
>>> 3741 0.440619 -0.38654536
>>> 762 -0.5636414 -0.5266918
>>> 3708 0.16183676 0.4607401
>>> 1406 -0.96252686 -0.95908827
>>> 2884 -1.0465598 -1.0781971
>>> 329 -0.20168936 -0.9614866
>>> 2397 3.243885 3.1847084
>>> 4317 -1.0641034 -1.2606155
>>> 3753 0.048048876 -0.346775
>>> 4118 -0.91082746 -1.1089246
>>> 34 -1.3283527 -1.2081558
>>> 3348 -0.63610536 -0.85158724
>>> 821 -1.0399052 -0.6266016
>>> 1438 1.1579788 1.120841
>>> 287 0.5642161 0.32640976
>>> 2414 0.96883076 1.0957055
>>> 4731 1.4760131 1.569379
>>> 3943 -0.4632675 -0.3675718
>>> 4413 -0.6153543 -1.5827011
>>> 2161 2.7869306 1.8072159
>>> 2040 1.2396694 1.6817431
>>> 1656 -2.092463 -1.2535402
>>> 4102 -0.9908664 -1.2052647
>>> 2989 -0.015770208 0.290952
>>> 581 -0.76243174 -0.8375981
>>> 1104 -0.62488604 -0.37863603
>>> 2080 2.2162127 2.0499284
>>> 2412 0.20095208 0.45734257
>>> 1439 1.7077768 0.84496367
>>> 1684 -0.21150896 -0.20693418
>>> 2240 1.0845501 1.5291333
>>> 1558 -1.0452496 -0.64865845
>>> 4277 2.5911071 2.526358
>>> 4310 -0.23622583 -0.505775
>>> 2533 -0.8236275 -0.3140184
>>> 1146 0.47433674 0.8601861
>>> 2856 -0.5063084 -0.94690484
>>> 416 -0.8424915 -0.8507677
>>> 3796 -0.49416366 0.032965228
>>> 1602 -0.00540107 0.14919552
>>> 3356 0.28803214 0.76078767
>>> 3458 1.517466 1.4855325
>>> 2478 1.3284727 0.2773125
>>> 2495 0.3790082 0.4190265
>>> 3518 -0.5543066 -0.66432804
>>> 4589 1.201527 1.3886311
>>> 3866 -0.8928671 -0.27537063
>>> 60 -0.8041529 -0.941777
>>> 2255 -0.55653214 -0.82440484
>>> 788 -0.6885363 -0.6883473
>>> 1118 -0.6767394 -1.0520471
>>> 1792 -0.24646327 -0.3136756
>>> 4104 -0.36181694 -0.4729737
>>> 713 1.3276731 1.4525069
>>> 3561 1.1067414 1.2752537
>>> 4410 -1.4161736 -0.9151406
>>> 4372 0.93627024 0.9698247
>>> 3727 -0.1570477 -0.41550815
>>> 2301 -0.3885044 -0.46667692
>>> 4557 -1.1161851 -1.0672038
>>> 3881 3.6827636 1.9129668
>>> 936 -1.1071701 -0.71526504
>>> 455 -0.8120595 -0.3771107
>>> 538 0.874878 0.37382558
>>> 874 0.6014724 0.9259041
>>> 268 -0.8192963 -0.6792366
>>> 3815 -1.5794114 -1.7127838
>>> 545 -0.5305388 -0.30873802
>>> 2388 0.8287904 0.7606985
>>> 4701 1.1278222 1.9024097
>>> 1551 -0.24893416 -0.42040047
>>> 1258 -0.9594762 -0.5790804
>>> 413 -0.6315382 -0.61940336
>>> 4489 0.060007297 -0.18692079
>>> 4011 -0.548491 -0.71731335
>>> 3556 0.2860971 0.35965604
>>> 3527 -0.6803107 -0.6846852
>>> 93 -1.51474 -1.277389
>>> 1524 -0.5053028 0.031222243
>>> 1007 -0.8441268 -1.0340606
>>> 2359 0.16999826 -0.011423737
>>> 2023 0.09211625 0.62565315
>>> 2566 1.6088505 0.15281136
>>> 126 -1.0538303 -1.1441997
>>> 2201 -1.2115248 -1.7858404
>>> 443 1.5913395 1.2955613
>>> 4477 -0.6345279 -0.85090256
>>> 3132 0.02297899 0.09475416
>>> 2578 2.163856 0.10013227
>>> 3095 0.8313305 0.7369955
>>> 3860 -0.99577105 -0.37749144
>>> 4321 -0.5251936 -0.396683
>>> 3072 0.2771404 -0.38408157
>>> 3656 1.0584921 0.94423187
>>> 1649 -1.1788175 -0.22005893
>>> 2483 -0.48046637 -0.07238129
>>> 2227 0.4091365 0.43606266
>>> 1647 -1.4550912 -1.1687906
>>> 434 -1.0769453 -0.97773874
>>> 508 0.71550345 0.91842407
>>> 4030 -0.9724724 -1.2190195
>>> 32 -1.0144738 -1.0827199
>>> 2378 1.2554752 1.2429152
>>> 2072 -0.29621848 -0.36302394
>>> 4295 -1.2732406 -1.7033901
>>> 2880 -0.84800845 -1.2739333
>>> 3895 0.21886146 0.05805583
>>> 3367 -0.6830394 -0.72197926
>>> 2819 0.9916661 0.97778416
>>> 180 -0.6034696 -0.5545162
>>> 2871 -0.02298058 -0.25663075
>>> 1282 -0.13555674 -0.08100193
>>> 4726 3.3202038 3.1711164
>>> 2046 -0.3958796 -0.5872211
>>> 4360 -0.20757169 -0.0917158
>>> 2174 -0.8792157 -0.876432
>>> 4391 -0.92508626 -0.7787754
>>> 719 0.05733386 -0.15424003
>>> 3892 0.99644536 0.49653107
>>> 295 0.9211319 0.4886034
>>> 3963 0.2800864 0.54985696
>>> 794 -0.72247225 -0.7841248
>>> 3665 -1.074838 -0.6648822
>>> 4201 1.6159328 1.4622109
>>> 3143 0.051522993 0.30459905
>>> 3306 -0.6112049 -0.22016367
>>> 2395 -1.1038252 -0.70158327
>>> 922 -0.41235054 -1.0664775
>>> 4007 0.023495713 -0.5092113
>>> 2467 -1.4061968 -1.1562213
>>> 2557 0.84699005 0.54351676
>>> 3121 -0.81999934 -0.60471857
>>> 1326 0.29189464 0.26175588
>>> 4542 2.3729944 2.3006575
>>> 3273 -1.0975051 -1.4864726
>>> 915 -1.7742411 -1.4512875
>>> 1425 1.2771043 1.1066712
>>> 231 -0.001554758 -0.0115439445
>>> 2778 -0.15709233 -0.49550366
>>> 1474 0.5618798 -0.32423294
>>> 1221 0.4606435 0.5954359
>>> 2751 -0.4219523 -0.33598366
>>> 2917 0.36709163 1.0571821
>>> 1100 -0.36901727 -0.8646418
>>> 1257 -0.40747365 -0.5442681
>>> 1888 0.41414487 1.2519577
>>> 1922 -0.011388625 0.09638521
>>> 687 -0.6026876 -1.2614013
>>> 4610 -1.4597112 -1.4582664
>>> 2599 -0.7272424 -1.030478
>>> 2795 -0.29068187 -0.3152506
>>> 4063 1.4626462 2.1924312
>>> 3092 1.1195902 1.654482
>>> 4028 1.6125013 0.9217905
>>> 2625 1.2405812 1.5339406
>>> 89 0.5569525 0.35653377
>>> 2446 0.71012634 0.53840303
>>> 113 -1.1779362 -0.83875966
>>> 1235 -1.0765408 -1.0651127
>>> 3476 -0.1699354 -0.66391885
>>> 2936 -0.046598837 -0.5868491
>>> 191 -1.0875645 -1.2574604
>>> 3839 -1.6475681 -1.3802075
>>> 2341 1.0695937 0.86223215
>>> 2945 -0.057609595 -0.43628183
>>> 16 -1.534198 -1.3754666
>>> 4576 3.9572244 3.9418137
>>> 3295 -0.20201539 0.293746
>>> 4344 0.8414983 -0.100360595
>>> 3261 -0.38751996 -0.28864902
>>> 3463 0.50136656 0.20311996
>>> 1760 -0.41102144 -0.702225
>>> 4166 -0.2991508 -0.8824803
>>> 2747 2.3169615 2.2081828
>>> 4254 -0.8023183 -0.9592501
>>> 1557 -0.27081808 -0.5626731
>>> 2159 2.4671519 1.9817302
>>> 1755 -0.2257704 -0.24101867
>>> 3178 0.34864894 0.25921702
>>> 1871 -0.7672431 -0.71121293
>>> 1759 -0.46570793 0.11003722
>>> 3486 0.5275994 0.6242777
>>> 1312 -0.6152286 -0.66084856
>>> 2425 -0.8782206 -0.39610785
>>> 2999 0.842043 0.69708604
>>> 4050 1.3270625 1.3482598
>>> 672 1.2893723 1.1946955
>>> 3310 -0.41426003 -0.17315364
>>> 4462 1.2846575 1.4006019
>>> 3034 -0.11991107 -0.2887737
>>> 1248 -0.5823968 -0.7410249
>>> 1794 -1.3655338 -0.9104022
>>> 2213 0.9052141 1.062428
>>> 2654 0.5142607 -0.04848281
>>> 1662 0.63029563 -0.10815069
>>> 1128 0.5356618 1.2625004
>>> 3200 1.197928 0.10284214
>>> 4747 -0.6134806 -0.20169565
>>> 3918 1.4647708 1.0231686
>>> 2289 -0.73930174 -0.6909877
>>> 845 0.22633392 0.04842783
>>> 3655 0.9034063 0.8930153
>>> 2010 -0.13900235 0.11913915
>>> 3940 -0.7778068 -0.47229043
>>> 3078 0.36089557 0.5922974
>>> 4525 0.506575 0.83493084
>>> 1427 1.403242 1.9667991
>>> 2270 -0.07931965 0.5135386
>>> 1105 -0.6805163 -0.6417121
>>> 361 -0.16465278 0.11917467
>>> 892 1.4800932 1.050355
>>> 2574 -0.6513742 -0.9479454
>>> 1061 -0.42918256 0.5216439
>>> 14 0.3766624 0.2842954
>>> 2666 -1.1571989 -0.46720338
>>> 1543 1.1789078 0.882945
>>> 1378 -0.045034282 0.22376238
>>> 3622 1.7089394 1.2542872
>>> 3539 -0.7119147 -0.47297513
>>> 3084 -0.56938964 -0.5392967
>>> 3230 0.86108834 0.31021222
>>> 464 0.7673291 -0.32167095
>>> 3358 0.012351639 -0.021510176
>>> 4501 -1.6101024 -1.5825592
>>> 2490 0.80881894 1.3378873
>>> 609 -1.3579831 -1.0990998
>>> 2637 1.1453823 0.83046854
>>> 133 1.0549593 0.68078244
>>> 4097 -0.56959474 -0.35363093
>>> 293 -1.3388032 -0.73687273
>>> 3101 0.62499917 0.5455417
>>> 3406 0.0786676 -0.1731901
>>> 3573 0.38165322 0.5564823
>>> 3155 1.1103164 1.5238969
>>> 881 -0.9533992 -0.8392399

Mean MAE across splits 2.859086183603462 +- 0.0
delta MAE: 5.26e-08
