namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-noH-ns64-nv48-d48-layers3-energy-mlp-both', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=True, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=0.0001)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo/231004-153924.661827-briling.best_checkpoint.pt', CV=1, num_epochs=177, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=True, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=0.0001, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles_mapped.noH.v6'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.7495

CV iter 1/1
Using random splits
total / train / test / val: 5265 4738 263 264
trainable params in model:  10352166
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo/231004-153924.661827-briling.best_checkpoint.pt
num epochs: 177
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 0.0001
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.749544941439076
Statistics on val_best_checkpoint
mae: 2.348280770200759
MSELoss: 0.11122414032279541
mean_pred: 0.07240553121223595
std_pred: 1.0154679535013256
mean_targets: 0.07679443648367217
std_targets: 1.0336712643955692
Evaluating on test, with test size:  263
Statistics on test_split_1
mae: 2.40324556749935
MSELoss: 0.11434621967826829
mean_pred: 0.0729096858113101
std_pred: 0.9912855896082792
mean_targets: 0.04491105969205047
std_targets: 1.0000618307879476
>>> 3427 0.9854133 0.6931589
>>> 2969 -0.48986357 -0.45484206
>>> 1507 -0.118455514 -0.5014591
>>> 1873 -1.2048843 -1.724388
>>> 4602 1.2649848 1.4604907
>>> 4313 -0.7359227 -0.8167812
>>> 3891 1.0824869 1.2812414
>>> 389 1.0824761 1.0188681
>>> 1734 -0.5248551 -0.24014375
>>> 3741 -0.19380455 -0.4312948
>>> 762 -1.1459903 -0.9132117
>>> 3708 -1.0989676 -1.289115
>>> 1406 0.96783936 1.6764451
>>> 2884 0.078315385 -0.05122485
>>> 329 -0.18394378 -0.5343774
>>> 2397 0.079619505 0.07126594
>>> 4763 -1.0380843 -0.8594837
>>> 3753 4.2243543 3.002992
>>> 4118 -0.3551441 -0.31811047
>>> 34 -0.8850752 -0.762179
>>> 3348 -1.6992149 -1.5743557
>>> 821 0.62422055 0.82242155
>>> 1438 -0.4904013 -0.6049088
>>> 287 -0.73073024 -0.75543904
>>> 2414 -1.3387135 -1.0334705
>>> 5260 -0.59079504 -0.9244613
>>> 4628 0.86913526 1.0707866
>>> 3943 0.43094942 0.64212304
>>> 4943 -1.0056231 -0.90368843
>>> 2161 2.1892185 2.3589382
>>> 2040 -0.39464545 -0.2426497
>>> 1656 0.7718347 1.1005893
>>> 4102 0.86050844 0.9554994
>>> 2989 -0.24927124 -0.12331384
>>> 581 -0.79960346 -0.44758606
>>> 1104 0.52041733 0.39958343
>>> 2080 -1.3161067 -0.7710502
>>> 2412 -1.1536646 -0.6918003
>>> 1439 -0.5633702 -0.5156658
>>> 1684 0.17579384 -0.13334808
>>> 2240 2.4692314 2.46069
>>> 1558 -0.12675881 -0.05992926
>>> 4277 0.21259287 0.052568547
>>> 4310 -0.3180282 -0.82372874
>>> 2533 -1.1659393 -0.63342917
>>> 1146 -0.72407186 -0.61531353
>>> 2856 1.9130968 1.8327507
>>> 4454 -0.58361924 -0.42834324
>>> 416 0.3344546 0.5585678
>>> 3796 -0.33325037 -0.7827964
>>> 1602 -0.29616007 0.10055772
>>> 3356 -0.16566099 -0.3237467
>>> 4692 -0.65213645 -0.59833556
>>> 4993 0.23447768 0.74149454
>>> 3458 0.9054166 1.1927115
>>> 2478 -0.7151388 -0.3902669
>>> 2495 -0.45305735 -0.5895903
>>> 3518 -0.2240947 -0.07459807
>>> 5068 0.42654705 0.59275556
>>> 3866 1.800198 1.5650636
>>> 60 0.1453533 0.2708124
>>> 2255 -0.50973004 -0.56641424
>>> 788 1.4696931 0.92325103
>>> 1118 -0.16407719 -0.736568
>>> 4384 -1.4179078 -1.4598429
>>> 1792 2.6479695 2.4368849
>>> 4104 0.95539653 0.5355545
>>> 713 -0.65285057 0.18670544
>>> 3561 1.2462696 1.4639829
>>> 4864 0.57211405 0.46381727
>>> 4823 -0.80591583 -0.47828
>>> 3727 0.8149332 0.8657972
>>> 2301 0.6740353 0.7783456
>>> 5034 0.59148645 0.41234562
>>> 3881 1.067551 1.2262856
>>> 936 -1.0131942 -0.7457968
>>> 455 -0.7084833 -0.1974484
>>> 538 -2.0819807 -1.7502099
>>> 874 0.41173407 0.5712114
>>> 268 -1.0423062 -0.49075007
>>> 3815 -0.9400258 -1.4337342
>>> 545 -0.3392587 -0.35416827
>>> 2388 -0.89385873 0.15059891
>>> 5187 1.3367939 1.0354793
>>> 1551 0.6048203 1.3088812
>>> 1258 -0.4096565 -0.31195107
>>> 413 0.64435947 0.74783814
>>> 4923 0.81618345 0.7297679
>>> 4011 0.3855116 0.2541183
>>> 5006 3.3586092 3.5182123
>>> 4496 -0.04389019 0.17360666
>>> 3556 -1.2309418 -1.3081949
>>> 3527 0.115157485 -0.03960841
>>> 93 0.36529642 0.36773336
>>> 1524 -0.52504843 -0.5069109
>>> 1007 0.56860334 0.40282807
>>> 2359 0.8517769 0.89047146
>>> 2023 0.86092716 1.0415784
>>> 2566 0.42706263 0.8774555
>>> 126 0.7298825 1.2851969
>>> 2201 -0.534558 -0.23356688
>>> 5124 1.240775 0.8589183
>>> 443 0.60317254 0.6472825
>>> 4938 2.8083868 2.5079255
>>> 3132 -0.086897515 -0.38706782
>>> 2578 -0.22242504 0.081759356
>>> 3095 -0.08774574 -0.08753043
>>> 3860 0.15853563 0.24253526
>>> 4321 -0.4383016 -0.4789764
>>> 3072 -0.63700783 -0.6891705
>>> 3656 -1.6025225 -1.6558763
>>> 1649 0.6768874 0.3629602
>>> 2483 -0.52018505 0.07750479
>>> 2227 -0.5221689 -0.3752028
>>> 1647 0.86279935 0.5492382
>>> 434 -1.047715 -1.2324342
>>> 508 -0.85811704 -0.9034106
>>> 4030 0.6077257 0.61564595
>>> 32 -0.5955355 -0.83697927
>>> 2378 -0.7314043 -0.8367969
>>> 2072 0.9554861 0.37491557
>>> 4295 0.4805775 0.48452768
>>> 2880 -0.104431055 -0.14528659
>>> 3895 0.43495166 0.25750956
>>> 3367 1.5858333 1.6675869
>>> 2819 0.7826891 0.21892455
>>> 180 -0.8510063 -0.7479987
>>> 2871 -0.2739499 -0.16833863
>>> 1282 -0.9522805 -0.53982824
>>> 5213 3.1486168 3.6834636
>>> 2046 -0.9065249 -0.936302
>>> 4360 -0.8300339 -0.64674306
>>> 2174 -0.64907783 -0.41789985
>>> 4391 0.95099247 1.2131531
>>> 719 -0.81877595 -0.47088516
>>> 3892 -0.40650415 -0.88871884
>>> 295 -1.0126419 -1.0530151
>>> 3963 -0.8863114 -0.8485004
>>> 794 0.17252013 -0.060568236
>>> 4756 2.4466553 2.3446217
>>> 3665 -0.9118003 -0.9043894
>>> 4591 2.298724 2.5725348
>>> 4201 -0.8030521 -0.6930691
>>> 3143 -0.8748716 -0.7315565
>>> 3306 -0.8075995 -0.57117987
>>> 2395 -0.25683013 -0.12730405
>>> 4841 0.08862804 0.07767875
>>> 922 0.15353237 -0.119000964
>>> 4007 2.2204604 3.0784395
>>> 2467 0.5246872 0.79935825
>>> 2557 1.8430104 1.2882136
>>> 3121 1.0890626 2.4370942
>>> 1326 0.28108397 0.7834844
>>> 5015 2.2072477 1.9661583
>>> 3273 1.184379 1.340362
>>> 4765 -0.3995782 -0.08454772
>>> 915 -1.1135755 -1.2095382
>>> 1425 -0.8721462 -1.4541528
>>> 231 -0.9382221 -1.1637627
>>> 2778 -1.5255634 -1.4129575
>>> 1474 -1.3552707 -0.35416535
>>> 1221 -0.7471962 -0.84586895
>>> 2751 -0.32799447 0.88301826
>>> 2917 -0.11810782 -0.45602703
>>> 1100 -0.7850239 -0.8095715
>>> 1257 -0.6603512 -0.701385
>>> 1888 -0.13042824 -0.29519448
>>> 1922 -0.7744876 -0.30526617
>>> 687 -0.5633804 -0.6100027
>>> 5090 -1.525454 -1.141049
>>> 2599 -0.5717533 -1.0795337
>>> 2795 0.0918363 0.5270085
>>> 4063 1.7279608 1.8434442
>>> 4703 0.48772874 0.62401104
>>> 3092 1.0007716 0.9961492
>>> 4904 0.7123427 0.866747
>>> 4636 0.31645447 0.28447336
>>> 4028 1.3167495 1.0607957
>>> 2625 -0.95792514 -1.0714576
>>> 89 0.4374601 0.193975
>>> 2446 -0.15745026 0.2342011
>>> 113 -0.6479383 -0.8390971
>>> 1235 0.39691412 0.8368346
>>> 3476 -0.7432795 -0.4822282
>>> 2936 0.18682653 0.39295414
>>> 191 -0.6031506 -0.42953938
>>> 3839 0.19065048 0.14288735
>>> 2341 -0.49323034 -0.694574
>>> 2945 -1.5404946 -1.240014
>>> 16 -1.481951 -1.2587845
>>> 5053 -1.5997279 -1.7907008
>>> 3295 -0.7824881 -1.0867699
>>> 4344 -0.17594704 -0.054022588
>>> 3261 -0.43556464 -0.6655059
>>> 3463 1.00464 -0.25975233
>>> 1760 -0.8717825 -0.7009673
>>> 4166 0.8144187 0.62137777
>>> 2747 -0.88440424 -0.08142742
>>> 4254 0.9611274 1.201157
>>> 1557 0.28128636 0.45438632
>>> 2159 2.4096243 2.3087716
>>> 1755 -0.25129682 -0.32882288
>>> 3178 0.34251603 0.47745654
>>> 1871 0.7388451 0.71090186
>>> 1759 -0.70780104 -0.79784226
>>> 4867 -1.4370874 -0.810961
>>> 3486 -0.16106483 -0.30442175
>>> 1312 -0.91509414 -0.94978446
>>> 2425 1.5198538 0.6080613
>>> 2999 -0.96374947 -0.55452013
>>> 4050 -1.2514888 -1.199371
>>> 672 0.5731096 0.7885252
>>> 3310 0.5672021 0.38011298
>>> 4462 2.8452923 3.2998686
>>> 3034 -0.8160722 -0.7069311
>>> 4610 2.1884248 2.3841677
>>> 1248 -0.82479984 -0.8260196
>>> 1794 1.133099 1.0390471
>>> 4947 -1.2046875 -1.507861
>>> 2213 1.1214687 1.0297481
>>> 2654 0.660169 0.7676797
>>> 1662 -0.7343415 -0.9367032
>>> 1128 -1.3053776 -1.1304622
>>> 3200 -0.8356322 -0.70486665
>>> 5236 0.5745594 0.46874753
>>> 3918 0.38709608 0.38924977
>>> 2289 1.2945144 1.3273327
>>> 845 0.3371095 0.45305094
>>> 3655 0.29316455 0.459143
>>> 2010 -0.14096348 0.040168263
>>> 3940 -1.4787211 -1.0649331
>>> 3078 -1.6118894 -1.8786823
>>> 4994 0.43318433 0.57652634
>>> 1427 1.3787518 1.4046191
>>> 2270 -0.53172576 -0.42652228
>>> 4645 0.8876004 1.0966865
>>> 1105 0.6337734 0.4969863
>>> 361 -0.7956073 -0.78712875
>>> 892 0.5586905 0.6251761
>>> 2574 1.2210029 0.90582895
>>> 4541 1.0764499 1.0164089
>>> 1061 -0.41127494 -0.7658645
>>> 4576 0.7761711 0.27922168
>>> 4736 -1.2621337 -1.2730892
>>> 4721 1.0016744 1.0509475
>>> 14 0.32229695 0.3046634
>>> 2666 1.4857376 0.57223725
>>> 1543 -1.2251798 -1.3914522
>>> 1378 -0.94246113 -0.61613166
>>> 3622 0.3639305 0.3467199
>>> 3539 -0.73182577 -0.34387663
>>> 3084 0.17540514 0.06756135
>>> 3230 0.47859722 0.42098036
>>> 464 -0.72558933 -1.0226139
>>> 3358 0.80648726 0.4137579
>>> 4501 0.7480878 0.73181283
>>> 2490 0.02491854 -0.4346503
>>> 4550 -0.60981584 -0.60984266
>>> 4725 0.23812722 -0.13246371
>>> 609 -1.3097639 -1.7594799
>>> 2637 -0.31165734 -0.5852918
>>> 133 -1.1240059 -1.0240173
>>> 4097 1.120926 0.82968795

Mean MAE across splits 2.40324556749935 +- 0.0
delta MAE: 7.48e-08
