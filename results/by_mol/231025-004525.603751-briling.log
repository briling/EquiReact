namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-xtb-noH-ns64-nv48-d48-layers3-energy-mlp-both-truemapping', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=False, random_baseline=False, two_layers_atom_diff=True, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=0.0001)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo-xtb/231005-004714.336719-briling.best_checkpoint.pt', CV=1, num_epochs=124, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=False, random_baseline=False, two_layers_atom_diff=True, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=0.0001, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles_mapped.noH.xtb.v6'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.2056

CV iter 1/1
Using random splits
total / train / test / val: 4774 4297 239 238
trainable params in model:  10383318
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo-xtb/231005-004714.336719-briling.best_checkpoint.pt
num epochs: 124
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 0.0001
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.205589010570657
Statistics on val_best_checkpoint
mae: 2.970763640327528
MSELoss: 0.1970985257377227
mean_pred: -0.042011227707068124
std_pred: 0.83483979900678
mean_targets: -0.018896354362368584
std_targets: 0.936119427283605
Evaluating on test, with test size:  239
Statistics on test_split_1
mae: 3.0429110191981406
MSELoss: 0.20070892870426177
mean_pred: -0.017776687691609065
std_pred: 0.9336279928684235
mean_targets: 0.03807484780748685
std_targets: 1.0444153835376104
>>> 1873 -0.804314 -0.49922723
>>> 3891 0.5844579 0.99763775
>>> 389 -0.7753813 -0.46374282
>>> 1734 -1.0032009 -0.7336661
>>> 3741 0.440619 0.3775014
>>> 762 -0.5636414 -0.70204365
>>> 3708 0.16183676 0.61451405
>>> 1406 -0.96252686 -1.181213
>>> 2884 -1.0465598 -1.036444
>>> 329 -0.20168936 -0.5281868
>>> 2397 3.243885 3.1337001
>>> 4317 -1.0641034 -1.2246102
>>> 3753 0.048048876 0.13326976
>>> 4118 -0.91082746 -0.91916776
>>> 34 -1.3283527 -1.0456996
>>> 3348 -0.63610536 -0.9018886
>>> 821 -1.0399052 -0.507996
>>> 1438 1.1579788 0.84585434
>>> 287 0.5642161 0.31395698
>>> 2414 0.96883076 0.7109035
>>> 4731 1.4760131 1.1115518
>>> 3943 -0.4632675 -0.68199944
>>> 4413 -0.6153543 -1.2562519
>>> 2161 2.7869306 1.9157127
>>> 2040 1.2396694 1.726285
>>> 1656 -2.092463 -1.157705
>>> 4102 -0.9908664 -1.0251744
>>> 2989 -0.015770208 0.17279267
>>> 581 -0.76243174 -0.662888
>>> 1104 -0.62488604 0.28077552
>>> 2080 2.2162127 1.8350115
>>> 2412 0.20095208 0.13639733
>>> 1439 1.7077768 0.84823763
>>> 1684 -0.21150896 -0.29108226
>>> 2240 1.0845501 1.747126
>>> 1558 -1.0452496 -0.8004944
>>> 4277 2.5911071 2.268015
>>> 4310 -0.23622583 -0.5342399
>>> 2533 -0.8236275 -0.23769051
>>> 1146 0.47433674 0.4329344
>>> 2856 -0.5063084 -0.8374214
>>> 416 -0.8424915 -0.86114806
>>> 3796 -0.49416366 -0.2125299
>>> 1602 -0.00540107 0.45518544
>>> 3356 0.28803214 0.46705934
>>> 3458 1.517466 1.8271866
>>> 2478 1.3284727 0.64745396
>>> 2495 0.3790082 0.8205302
>>> 3518 -0.5543066 -1.040668
>>> 4589 1.201527 1.0643743
>>> 3866 -0.8928671 -0.47529522
>>> 60 -0.8041529 -0.8732884
>>> 2255 -0.55653214 -0.5897279
>>> 788 -0.6885363 -0.51548696
>>> 1118 -0.6767394 -1.1103382
>>> 1792 -0.24646327 -0.6042164
>>> 4104 -0.36181694 -0.39805555
>>> 713 1.3276731 1.150931
>>> 3561 1.1067414 1.178297
>>> 4410 -1.4161736 -0.9071635
>>> 4372 0.93627024 1.5338591
>>> 3727 -0.1570477 -0.39711314
>>> 2301 -0.3885044 -0.296257
>>> 4557 -1.1161851 -0.9578481
>>> 3881 3.6827636 1.8415686
>>> 936 -1.1071701 -0.7712762
>>> 455 -0.8120595 -0.5440513
>>> 538 0.874878 0.21297371
>>> 874 0.6014724 0.4306411
>>> 268 -0.8192963 -0.861485
>>> 3815 -1.5794114 -1.4691528
>>> 545 -0.5305388 -0.5072995
>>> 2388 0.8287904 0.8317615
>>> 4701 1.1278222 1.8016943
>>> 1551 -0.24893416 -0.39430153
>>> 1258 -0.9594762 -0.56262183
>>> 413 -0.6315382 -0.6796271
>>> 4489 0.060007297 0.048859242
>>> 4011 -0.548491 -0.76293623
>>> 3556 0.2860971 -0.16141164
>>> 3527 -0.6803107 -0.8000434
>>> 93 -1.51474 -1.1405218
>>> 1524 -0.5053028 -0.02184616
>>> 1007 -0.8441268 -1.1361202
>>> 2359 0.16999826 0.11378074
>>> 2023 0.09211625 0.54555523
>>> 2566 1.6088505 -0.009769211
>>> 126 -1.0538303 -1.3583376
>>> 2201 -1.2115248 -1.3970002
>>> 443 1.5913395 1.4542493
>>> 4477 -0.6345279 -0.9188366
>>> 3132 0.02297899 0.3469146
>>> 2578 2.163856 0.0912252
>>> 3095 0.8313305 0.6574869
>>> 3860 -0.99577105 -0.9370974
>>> 4321 -0.5251936 -0.21466535
>>> 3072 0.2771404 -0.062777
>>> 3656 1.0584921 0.6811141
>>> 1649 -1.1788175 -0.45111686
>>> 2483 -0.48046637 0.0271343
>>> 2227 0.4091365 0.7002554
>>> 1647 -1.4550912 -1.247107
>>> 434 -1.0769453 -0.97739923
>>> 508 0.71550345 0.64622647
>>> 4030 -0.9724724 -0.7941233
>>> 32 -1.0144738 -0.9866668
>>> 2378 1.2554752 1.3652086
>>> 2072 -0.29621848 -0.33448857
>>> 4295 -1.2732406 -1.6561755
>>> 2880 -0.84800845 -1.1092019
>>> 3895 0.21886146 0.13485445
>>> 3367 -0.6830394 -0.43320954
>>> 2819 0.9916661 0.95632684
>>> 180 -0.6034696 -0.5568613
>>> 2871 -0.02298058 -0.34723565
>>> 1282 -0.13555674 -0.092683494
>>> 4726 3.3202038 3.0217817
>>> 2046 -0.3958796 -0.56448853
>>> 4360 -0.20757169 -0.34786332
>>> 2174 -0.8792157 -0.8196909
>>> 4391 -0.92508626 -0.538017
>>> 719 0.05733386 -0.14208928
>>> 3892 0.99644536 0.47430447
>>> 295 0.9211319 0.95930994
>>> 3963 0.2800864 0.64312714
>>> 794 -0.72247225 -0.66679335
>>> 3665 -1.074838 -0.5128125
>>> 4201 1.6159328 0.6912858
>>> 3143 0.051522993 0.4661127
>>> 3306 -0.6112049 -0.49713182
>>> 2395 -1.1038252 -0.63842183
>>> 922 -0.41235054 -1.3253399
>>> 4007 0.023495713 -0.92985135
>>> 2467 -1.4061968 -1.1477004
>>> 2557 0.84699005 0.4903058
>>> 3121 -0.81999934 -0.17252192
>>> 1326 0.29189464 0.34015793
>>> 4542 2.3729944 2.0419428
>>> 3273 -1.0975051 -1.0928783
>>> 915 -1.7742411 -1.2295684
>>> 1425 1.2771043 0.75723994
>>> 231 -0.001554758 -0.060883887
>>> 2778 -0.15709233 -0.116386466
>>> 1474 0.5618798 -0.15612456
>>> 1221 0.4606435 0.39751658
>>> 2751 -0.4219523 -0.3281142
>>> 2917 0.36709163 0.5085886
>>> 1100 -0.36901727 -0.90878904
>>> 1257 -0.40747365 -0.14127925
>>> 1888 0.41414487 1.2923743
>>> 1922 -0.011388625 0.34571347
>>> 687 -0.6026876 -1.4479507
>>> 4610 -1.4597112 -1.6690112
>>> 2599 -0.7272424 -0.97279227
>>> 2795 -0.29068187 -0.3330117
>>> 4063 1.4626462 0.7431052
>>> 3092 1.1195902 1.227431
>>> 4028 1.6125013 0.46545392
>>> 2625 1.2405812 1.7436492
>>> 89 0.5569525 0.024006788
>>> 2446 0.71012634 -0.099508695
>>> 113 -1.1779362 -0.844456
>>> 1235 -1.0765408 -1.1822734
>>> 3476 -0.1699354 -0.49727443
>>> 2936 -0.046598837 -0.07711464
>>> 191 -1.0875645 -1.0925399
>>> 3839 -1.6475681 -1.5688163
>>> 2341 1.0695937 0.71329314
>>> 2945 -0.057609595 -0.34717506
>>> 16 -1.534198 -1.2026322
>>> 4576 3.9572244 4.0660014
>>> 3295 -0.20201539 0.033845257
>>> 4344 0.8414983 0.25279924
>>> 3261 -0.38751996 -0.6490306
>>> 3463 0.50136656 -0.18390429
>>> 1760 -0.41102144 -0.44210085
>>> 4166 -0.2991508 -0.59074354
>>> 2747 2.3169615 1.9163809
>>> 4254 -0.8023183 -0.5575092
>>> 1557 -0.27081808 -1.0816562
>>> 2159 2.4671519 2.2756586
>>> 1755 -0.2257704 -0.17622393
>>> 3178 0.34864894 -0.06612979
>>> 1871 -0.7672431 -0.5798579
>>> 1759 -0.46570793 0.20844465
>>> 3486 0.5275994 0.49286377
>>> 1312 -0.6152286 -0.36787033
>>> 2425 -0.8782206 -0.34400672
>>> 2999 0.842043 0.31020653
>>> 4050 1.3270625 1.0722215
>>> 672 1.2893723 0.5823869
>>> 3310 -0.41426003 -0.21614018
>>> 4462 1.2846575 1.2874404
>>> 3034 -0.11991107 -0.25934952
>>> 1248 -0.5823968 -0.37988582
>>> 1794 -1.3655338 -1.3656955
>>> 2213 0.9052141 1.2431588
>>> 2654 0.5142607 -0.49574256
>>> 1662 0.63029563 -0.0717895
>>> 1128 0.5356618 0.41939157
>>> 3200 1.197928 0.30604875
>>> 4747 -0.6134806 -0.626436
>>> 3918 1.4647708 0.9732601
>>> 2289 -0.73930174 -0.3240397
>>> 845 0.22633392 0.86517936
>>> 3655 0.9034063 0.8301702
>>> 2010 -0.13900235 0.08838226
>>> 3940 -0.7778068 -0.6617549
>>> 3078 0.36089557 0.21728143
>>> 4525 0.506575 0.56089765
>>> 1427 1.403242 1.3691999
>>> 2270 -0.07931965 0.2700582
>>> 1105 -0.6805163 -1.1692827
>>> 361 -0.16465278 0.108059764
>>> 892 1.4800932 1.0282283
>>> 2574 -0.6513742 -0.57152724
>>> 1061 -0.42918256 -0.11772452
>>> 14 0.3766624 0.4632667
>>> 2666 -1.1571989 -0.7828515
>>> 1543 1.1789078 1.1722685
>>> 1378 -0.045034282 0.41758102
>>> 3622 1.7089394 0.93424374
>>> 3539 -0.7119147 -0.40651295
>>> 3084 -0.56938964 -0.3648694
>>> 3230 0.86108834 0.57696986
>>> 464 0.7673291 -0.35616416
>>> 3358 0.012351639 -0.044169087
>>> 4501 -1.6101024 -1.1170236
>>> 2490 0.80881894 0.9693594
>>> 609 -1.3579831 -1.1000016
>>> 2637 1.1453823 1.0694233
>>> 133 1.0549593 0.19686857
>>> 4097 -0.56959474 -0.10752263
>>> 293 -1.3388032 -0.92243093
>>> 3101 0.62499917 0.60053205
>>> 3406 0.0786676 -0.29253483
>>> 3573 0.38165322 0.37642527
>>> 3155 1.1103164 1.3412654
>>> 881 -0.9533992 -1.449705

Mean MAE across splits 3.0429110191981406 +- 0.0
delta MAE: 0.00e+00
