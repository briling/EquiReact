namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-ns64-nv48-d48-layers3-energy-mlp-both-crossattention', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention='cross', sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=False, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=1e-05)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo/231004-153924.657478-briling.best_checkpoint.pt', CV=1, num_epochs=235, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention='cross', sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=False, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=1e-05, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles.v6'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.7495

CV iter 1/1
Using random splits
total / train / test / val: 5265 4738 263 264
trainable params in model:  10352166
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo/231004-153924.657478-briling.best_checkpoint.pt
num epochs: 235
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 1e-05
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.749544941439076
Statistics on val_best_checkpoint
mae: 2.5445579532158193
MSELoss: 0.12416192573128325
mean_pred: 0.0646749757456057
std_pred: 0.9319013366193483
mean_targets: 0.07679443648367217
std_targets: 1.0336712643955692
Evaluating on test, with test size:  263
Statistics on test_split_1
mae: 2.4803485498833027
MSELoss: 0.12501268314592767
mean_pred: 0.0642004484931628
std_pred: 0.9473549524943033
mean_targets: 0.04491105969205047
std_targets: 1.0000618307879476
>>> 3427 0.9854133 1.1260967
>>> 2969 -0.48986357 -0.44779003
>>> 1507 -0.118455514 -0.3361176
>>> 1873 -1.2048843 -1.6119401
>>> 4602 1.2649848 1.0083979
>>> 4313 -0.7359227 -0.72262186
>>> 3891 1.0824869 1.2746632
>>> 389 1.0824761 0.5307792
>>> 1734 -0.5248551 -0.440646
>>> 3741 -0.19380455 -0.5648332
>>> 762 -1.1459903 -0.96651524
>>> 3708 -1.0989676 -1.3107184
>>> 1406 0.96783936 1.8192999
>>> 2884 0.078315385 0.19073862
>>> 329 -0.18394378 -0.5805363
>>> 2397 0.079619505 0.08100701
>>> 4763 -1.0380843 -0.82743394
>>> 3753 4.2243543 2.3666844
>>> 4118 -0.3551441 -0.46289176
>>> 34 -0.8850752 -0.5677724
>>> 3348 -1.6992149 -1.4601815
>>> 821 0.62422055 0.64012796
>>> 1438 -0.4904013 -0.8432909
>>> 287 -0.73073024 -0.7857113
>>> 2414 -1.3387135 -1.2408347
>>> 5260 -0.59079504 -0.692521
>>> 4628 0.86913526 1.2969195
>>> 3943 0.43094942 0.60800487
>>> 4943 -1.0056231 -1.0299921
>>> 2161 2.1892185 1.990212
>>> 2040 -0.39464545 -0.24527913
>>> 1656 0.7718347 0.9753619
>>> 4102 0.86050844 0.9093744
>>> 2989 -0.24927124 -0.3638764
>>> 581 -0.79960346 -0.34719205
>>> 1104 0.52041733 0.38136235
>>> 2080 -1.3161067 -0.6520421
>>> 2412 -1.1536646 -0.8339829
>>> 1439 -0.5633702 -0.6311148
>>> 1684 0.17579384 -0.24125826
>>> 2240 2.4692314 2.4441006
>>> 1558 -0.12675881 -0.13125019
>>> 4277 0.21259287 0.08323919
>>> 4310 -0.3180282 -0.6155325
>>> 2533 -1.1659393 -0.84804416
>>> 1146 -0.72407186 -0.6701125
>>> 2856 1.9130968 2.4409413
>>> 4454 -0.58361924 -0.6522631
>>> 416 0.3344546 1.0002922
>>> 3796 -0.33325037 -0.86691356
>>> 1602 -0.29616007 0.2249067
>>> 3356 -0.16566099 -0.63886666
>>> 4692 -0.65213645 -0.2941473
>>> 4993 0.23447768 0.11406303
>>> 3458 0.9054166 0.9935245
>>> 2478 -0.7151388 -0.41522205
>>> 2495 -0.45305735 -0.31769827
>>> 3518 -0.2240947 0.23928751
>>> 5068 0.42654705 0.41379791
>>> 3866 1.800198 1.4982312
>>> 60 0.1453533 0.09554935
>>> 2255 -0.50973004 -0.6125471
>>> 788 1.4696931 0.688303
>>> 1118 -0.16407719 -0.6297871
>>> 4384 -1.4179078 -1.3322685
>>> 1792 2.6479695 3.0498886
>>> 4104 0.95539653 0.5899673
>>> 713 -0.65285057 0.39431334
>>> 3561 1.2462696 1.156007
>>> 4864 0.57211405 0.5870544
>>> 4823 -0.80591583 -0.64070576
>>> 3727 0.8149332 0.702988
>>> 2301 0.6740353 0.5130735
>>> 5034 0.59148645 0.55960244
>>> 3881 1.067551 1.117872
>>> 936 -1.0131942 -0.71451473
>>> 455 -0.7084833 -0.44935477
>>> 538 -2.0819807 -1.7985224
>>> 874 0.41173407 0.38852447
>>> 268 -1.0423062 -0.5431774
>>> 3815 -0.9400258 -1.1276486
>>> 545 -0.3392587 -0.121898174
>>> 2388 -0.89385873 0.16946346
>>> 5187 1.3367939 1.1627824
>>> 1551 0.6048203 1.1103833
>>> 1258 -0.4096565 -0.5534779
>>> 413 0.64435947 0.9222481
>>> 4923 0.81618345 0.88678193
>>> 4011 0.3855116 0.41140088
>>> 5006 3.3586092 3.352484
>>> 4496 -0.04389019 0.0773489
>>> 3556 -1.2309418 -1.2279737
>>> 3527 0.115157485 -0.4019108
>>> 93 0.36529642 0.4226418
>>> 1524 -0.52504843 -0.4722108
>>> 1007 0.56860334 0.9169285
>>> 2359 0.8517769 0.689482
>>> 2023 0.86092716 0.7437154
>>> 2566 0.42706263 0.11834589
>>> 126 0.7298825 1.2664974
>>> 2201 -0.534558 -0.21969663
>>> 5124 1.240775 1.1028587
>>> 443 0.60317254 0.62751764
>>> 4938 2.8083868 2.3300211
>>> 3132 -0.086897515 -0.4410467
>>> 2578 -0.22242504 -0.19207387
>>> 3095 -0.08774574 -0.30327824
>>> 3860 0.15853563 -0.16216402
>>> 4321 -0.4383016 -0.52017355
>>> 3072 -0.63700783 -0.796609
>>> 3656 -1.6025225 -1.5187107
>>> 1649 0.6768874 0.6506762
>>> 2483 -0.52018505 0.21860792
>>> 2227 -0.5221689 -0.5608461
>>> 1647 0.86279935 0.6349461
>>> 434 -1.047715 -1.4594027
>>> 508 -0.85811704 -0.85156107
>>> 4030 0.6077257 0.8078758
>>> 32 -0.5955355 -0.90989214
>>> 2378 -0.7314043 -0.73297167
>>> 2072 0.9554861 0.4476587
>>> 4295 0.4805775 0.69366026
>>> 2880 -0.104431055 0.09897124
>>> 3895 0.43495166 0.32368493
>>> 3367 1.5858333 1.6597762
>>> 2819 0.7826891 0.16482466
>>> 180 -0.8510063 -0.82515085
>>> 2871 -0.2739499 -0.13743928
>>> 1282 -0.9522805 -0.68822813
>>> 5213 3.1486168 3.5036201
>>> 2046 -0.9065249 -0.89564544
>>> 4360 -0.8300339 -0.2845659
>>> 2174 -0.64907783 -0.5267669
>>> 4391 0.95099247 0.8953169
>>> 719 -0.81877595 -0.3984016
>>> 3892 -0.40650415 -0.691881
>>> 295 -1.0126419 -0.8540453
>>> 3963 -0.8863114 -0.75929046
>>> 794 0.17252013 -0.16523102
>>> 4756 2.4466553 2.7648764
>>> 3665 -0.9118003 -0.8555951
>>> 4591 2.298724 2.157594
>>> 4201 -0.8030521 -0.723508
>>> 3143 -0.8748716 -0.72893816
>>> 3306 -0.8075995 -0.55042297
>>> 2395 -0.25683013 -0.12109381
>>> 4841 0.08862804 -0.08065417
>>> 922 0.15353237 0.017882295
>>> 4007 2.2204604 2.8412733
>>> 2467 0.5246872 0.5914207
>>> 2557 1.8430104 0.8644991
>>> 3121 1.0890626 2.2599308
>>> 1326 0.28108397 0.8018721
>>> 5015 2.2072477 1.6833345
>>> 3273 1.184379 1.1080098
>>> 4765 -0.3995782 -0.07911505
>>> 915 -1.1135755 -0.9347492
>>> 1425 -0.8721462 -0.9536554
>>> 231 -0.9382221 -0.6155042
>>> 2778 -1.5255634 -1.2042589
>>> 1474 -1.3552707 -0.4705794
>>> 1221 -0.7471962 -0.7370435
>>> 2751 -0.32799447 0.29313985
>>> 2917 -0.11810782 -0.25510123
>>> 1100 -0.7850239 -0.76472604
>>> 1257 -0.6603512 -0.65337944
>>> 1888 -0.13042824 -0.5266553
>>> 1922 -0.7744876 -0.31154075
>>> 687 -0.5633804 -1.0220914
>>> 5090 -1.525454 -1.1540246
>>> 2599 -0.5717533 -1.1117537
>>> 2795 0.0918363 0.3675543
>>> 4063 1.7279608 2.0803277
>>> 4703 0.48772874 0.68028057
>>> 3092 1.0007716 1.0174168
>>> 4904 0.7123427 0.23809403
>>> 4636 0.31645447 0.32913765
>>> 4028 1.3167495 1.1893243
>>> 2625 -0.95792514 -0.74310213
>>> 89 0.4374601 0.17840457
>>> 2446 -0.15745026 0.55894446
>>> 113 -0.6479383 -0.83185214
>>> 1235 0.39691412 0.25149235
>>> 3476 -0.7432795 -0.4678851
>>> 2936 0.18682653 0.33064285
>>> 191 -0.6031506 -0.5618404
>>> 3839 0.19065048 0.23376271
>>> 2341 -0.49323034 -0.6656616
>>> 2945 -1.5404946 -1.31723
>>> 16 -1.481951 -1.1078203
>>> 5053 -1.5997279 -1.5270865
>>> 3295 -0.7824881 -1.2196038
>>> 4344 -0.17594704 -0.36963946
>>> 3261 -0.43556464 -0.5499012
>>> 3463 1.00464 0.28923872
>>> 1760 -0.8717825 -0.664111
>>> 4166 0.8144187 0.50893575
>>> 2747 -0.88440424 -0.2797093
>>> 4254 0.9611274 1.2143836
>>> 1557 0.28128636 0.28575
>>> 2159 2.4096243 2.1467204
>>> 1755 -0.25129682 0.15576158
>>> 3178 0.34251603 0.39276895
>>> 1871 0.7388451 0.2725823
>>> 1759 -0.70780104 -0.67515105
>>> 4867 -1.4370874 -0.7797466
>>> 3486 -0.16106483 -0.38234615
>>> 1312 -0.91509414 -0.75715166
>>> 2425 1.5198538 -0.010477355
>>> 2999 -0.96374947 -0.4076059
>>> 4050 -1.2514888 -1.2285291
>>> 672 0.5731096 0.12862252
>>> 3310 0.5672021 0.26104736
>>> 4462 2.8452923 2.5383842
>>> 3034 -0.8160722 -0.7646823
>>> 4610 2.1884248 2.3039484
>>> 1248 -0.82479984 -0.61880416
>>> 1794 1.133099 1.1603404
>>> 4947 -1.2046875 -1.436352
>>> 2213 1.1214687 1.2192783
>>> 2654 0.660169 0.6457915
>>> 1662 -0.7343415 -0.5427983
>>> 1128 -1.3053776 -1.4446089
>>> 3200 -0.8356322 -0.7765279
>>> 5236 0.5745594 0.82379746
>>> 3918 0.38709608 0.1828425
>>> 2289 1.2945144 1.024147
>>> 845 0.3371095 0.34488812
>>> 3655 0.29316455 0.3846846
>>> 2010 -0.14096348 -0.011405962
>>> 3940 -1.4787211 -1.0520232
>>> 3078 -1.6118894 -1.5859178
>>> 4994 0.43318433 0.44527876
>>> 1427 1.3787518 1.0640187
>>> 2270 -0.53172576 -0.79806244
>>> 4645 0.8876004 1.0577922
>>> 1105 0.6337734 0.20047113
>>> 361 -0.7956073 -0.66005474
>>> 892 0.5586905 0.5261648
>>> 2574 1.2210029 0.85143846
>>> 4541 1.0764499 1.4060342
>>> 1061 -0.41127494 -0.34345037
>>> 4576 0.7761711 0.55595446
>>> 4736 -1.2621337 -1.0932101
>>> 4721 1.0016744 1.2790178
>>> 14 0.32229695 0.4776238
>>> 2666 1.4857376 0.8848266
>>> 1543 -1.2251798 -1.3891692
>>> 1378 -0.94246113 -0.63308406
>>> 3622 0.3639305 0.27405417
>>> 3539 -0.73182577 -0.36335438
>>> 3084 0.17540514 0.047981314
>>> 3230 0.47859722 0.4460142
>>> 464 -0.72558933 -0.70709944
>>> 3358 0.80648726 0.81355524
>>> 4501 0.7480878 0.68132323
>>> 2490 0.02491854 -0.14991763
>>> 4550 -0.60981584 -0.31273413
>>> 4725 0.23812722 0.007195387
>>> 609 -1.3097639 -1.0552585
>>> 2637 -0.31165734 -0.23455438
>>> 133 -1.1240059 -1.0413024
>>> 4097 1.120926 0.78179216

Mean MAE across splits 2.4803485498833027 +- 0.0
delta MAE: 2.86e-08
