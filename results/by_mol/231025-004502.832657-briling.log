namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-ns64-nv48-d48-layers3-energy-mlp-both-rxnmapper', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=True, random_baseline=False, two_layers_atom_diff=True, noH=False, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=0.0001)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo/231004-182624.780699-briling.best_checkpoint.pt', CV=1, num_epochs=214, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=True, random_baseline=False, two_layers_atom_diff=True, noH=False, reverse=False, split_complexes=False, xtb=False, semiempirical=False, lr=0.0005, weight_decay=0.0001, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles_rxnmapper_full.v6'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.7495

CV iter 1/1
Using random splits
total / train / test / val: 5265 4738 263 264
trainable params in model:  10383318
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo/231004-182624.780699-briling.best_checkpoint.pt
num epochs: 214
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 0.0001
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.749544941439076
Statistics on val_best_checkpoint
mae: 2.6110663480491967
MSELoss: 0.12963555087194298
mean_pred: 0.05427488345991482
std_pred: 0.9505950239571658
mean_targets: 0.07679443648367217
std_targets: 1.0336712643955692
Evaluating on test, with test size:  263
Statistics on test_split_1
mae: 2.7001601512232543
MSELoss: 0.14470521620277202
mean_pred: 0.0478770834478465
std_pred: 0.9541014676744287
mean_targets: 0.04491105969205047
std_targets: 1.0000618307879476
>>> 3427 0.9854133 0.7254634
>>> 2969 -0.48986357 -0.40246177
>>> 1507 -0.118455514 -0.6109016
>>> 1873 -1.2048843 -1.1158105
>>> 4602 1.2649848 1.0240047
>>> 4313 -0.7359227 -0.7039435
>>> 3891 1.0824869 1.0267729
>>> 389 1.0824761 0.82686955
>>> 1734 -0.5248551 0.010907635
>>> 3741 -0.19380455 -0.55094564
>>> 762 -1.1459903 -1.12764
>>> 3708 -1.0989676 -1.5907204
>>> 1406 0.96783936 1.3771185
>>> 2884 0.078315385 0.32366216
>>> 329 -0.18394378 -0.56481194
>>> 2397 0.079619505 0.10609487
>>> 4763 -1.0380843 -0.9248019
>>> 3753 4.2243543 2.6120543
>>> 4118 -0.3551441 -0.0031280573
>>> 34 -0.8850752 -1.0310249
>>> 3348 -1.6992149 -1.4045111
>>> 821 0.62422055 0.58835876
>>> 1438 -0.4904013 -0.47667688
>>> 287 -0.73073024 -0.8730817
>>> 2414 -1.3387135 -1.2962859
>>> 5260 -0.59079504 -0.6630596
>>> 4628 0.86913526 1.4493656
>>> 3943 0.43094942 0.6477239
>>> 4943 -1.0056231 -0.93864447
>>> 2161 2.1892185 2.3286424
>>> 2040 -0.39464545 -0.33790708
>>> 1656 0.7718347 1.1668608
>>> 4102 0.86050844 0.83681935
>>> 2989 -0.24927124 -0.3286059
>>> 581 -0.79960346 0.031256966
>>> 1104 0.52041733 -0.14378634
>>> 2080 -1.3161067 -0.87834656
>>> 2412 -1.1536646 -0.57480204
>>> 1439 -0.5633702 -0.4155062
>>> 1684 0.17579384 -0.14312373
>>> 2240 2.4692314 2.5955555
>>> 1558 -0.12675881 -0.050587967
>>> 4277 0.21259287 0.06875077
>>> 4310 -0.3180282 -0.6884189
>>> 2533 -1.1659393 -0.7653473
>>> 1146 -0.72407186 -0.49233148
>>> 2856 1.9130968 1.54858
>>> 4454 -0.58361924 -0.5515014
>>> 416 0.3344546 0.98168415
>>> 3796 -0.33325037 -0.6703865
>>> 1602 -0.29616007 -0.13977253
>>> 3356 -0.16566099 -0.67738855
>>> 4692 -0.65213645 -0.1861382
>>> 4993 0.23447768 0.26276457
>>> 3458 0.9054166 0.6260799
>>> 2478 -0.7151388 -0.40970552
>>> 2495 -0.45305735 -0.7103156
>>> 3518 -0.2240947 -0.16948745
>>> 5068 0.42654705 0.50550675
>>> 3866 1.800198 1.4805532
>>> 60 0.1453533 -0.39873296
>>> 2255 -0.50973004 -0.6401881
>>> 788 1.4696931 0.6843523
>>> 1118 -0.16407719 -1.0727882
>>> 4384 -1.4179078 -1.1736867
>>> 1792 2.6479695 2.186192
>>> 4104 0.95539653 0.7203844
>>> 713 -0.65285057 -0.56007797
>>> 3561 1.2462696 0.73208827
>>> 4864 0.57211405 0.65063244
>>> 4823 -0.80591583 -0.6125487
>>> 3727 0.8149332 0.8376622
>>> 2301 0.6740353 0.69566935
>>> 5034 0.59148645 0.5850106
>>> 3881 1.067551 1.0818646
>>> 936 -1.0131942 -0.80682874
>>> 455 -0.7084833 -0.16223094
>>> 538 -2.0819807 -2.7737606
>>> 874 0.41173407 0.56771594
>>> 268 -1.0423062 -0.8728825
>>> 3815 -0.9400258 -1.5927439
>>> 545 -0.3392587 -0.19328861
>>> 2388 -0.89385873 -0.28664353
>>> 5187 1.3367939 0.53817445
>>> 1551 0.6048203 0.96423656
>>> 1258 -0.4096565 0.04629545
>>> 413 0.64435947 0.46564662
>>> 4923 0.81618345 0.28939044
>>> 4011 0.3855116 0.401734
>>> 5006 3.3586092 3.3965626
>>> 4496 -0.04389019 -0.064695634
>>> 3556 -1.2309418 -0.9193522
>>> 3527 0.115157485 0.1252871
>>> 93 0.36529642 0.6048096
>>> 1524 -0.52504843 -0.8550379
>>> 1007 0.56860334 0.4238476
>>> 2359 0.8517769 0.57422984
>>> 2023 0.86092716 1.0435423
>>> 2566 0.42706263 0.42456266
>>> 126 0.7298825 1.3007478
>>> 2201 -0.534558 -0.33989996
>>> 5124 1.240775 0.8953673
>>> 443 0.60317254 0.6820624
>>> 4938 2.8083868 2.609297
>>> 3132 -0.086897515 -0.24633904
>>> 2578 -0.22242504 -0.2736474
>>> 3095 -0.08774574 -0.34884447
>>> 3860 0.15853563 0.50949425
>>> 4321 -0.4383016 -0.23719963
>>> 3072 -0.63700783 -0.68248236
>>> 3656 -1.6025225 -1.6131371
>>> 1649 0.6768874 0.6361856
>>> 2483 -0.52018505 0.55426127
>>> 2227 -0.5221689 -0.6475924
>>> 1647 0.86279935 0.6797345
>>> 434 -1.047715 -1.3231179
>>> 508 -0.85811704 -0.82504547
>>> 4030 0.6077257 0.9438714
>>> 32 -0.5955355 -0.9971797
>>> 2378 -0.7314043 -0.88129354
>>> 2072 0.9554861 0.5016667
>>> 4295 0.4805775 0.6121347
>>> 2880 -0.104431055 0.36461604
>>> 3895 0.43495166 0.5039575
>>> 3367 1.5858333 1.9532559
>>> 2819 0.7826891 0.7585303
>>> 180 -0.8510063 -0.8555221
>>> 2871 -0.2739499 -0.27303982
>>> 1282 -0.9522805 -0.7815508
>>> 5213 3.1486168 3.586364
>>> 2046 -0.9065249 -1.0867621
>>> 4360 -0.8300339 -0.098867565
>>> 2174 -0.64907783 -0.36157826
>>> 4391 0.95099247 0.7690851
>>> 719 -0.81877595 -0.5498946
>>> 3892 -0.40650415 -0.78190565
>>> 295 -1.0126419 -1.0356752
>>> 3963 -0.8863114 -0.7518214
>>> 794 0.17252013 -0.24799149
>>> 4756 2.4466553 2.8606918
>>> 3665 -0.9118003 -0.76814485
>>> 4591 2.298724 1.8927914
>>> 4201 -0.8030521 -0.76048064
>>> 3143 -0.8748716 -0.57096976
>>> 3306 -0.8075995 -0.612601
>>> 2395 -0.25683013 -0.23779656
>>> 4841 0.08862804 -0.0077825654
>>> 922 0.15353237 0.42565495
>>> 4007 2.2204604 1.9289142
>>> 2467 0.5246872 0.55680513
>>> 2557 1.8430104 1.4265298
>>> 3121 1.0890626 2.9629278
>>> 1326 0.28108397 0.7306559
>>> 5015 2.2072477 2.130887
>>> 3273 1.184379 1.033165
>>> 4765 -0.3995782 0.039564066
>>> 915 -1.1135755 -0.34201887
>>> 1425 -0.8721462 -1.2914802
>>> 231 -0.9382221 -0.46531683
>>> 2778 -1.5255634 -1.1204808
>>> 1474 -1.3552707 -0.82928205
>>> 1221 -0.7471962 -0.7918326
>>> 2751 -0.32799447 0.42137945
>>> 2917 -0.11810782 -0.14589085
>>> 1100 -0.7850239 -0.6052297
>>> 1257 -0.6603512 0.14898106
>>> 1888 -0.13042824 -0.42408717
>>> 1922 -0.7744876 -0.2041694
>>> 687 -0.5633804 -0.78304756
>>> 5090 -1.525454 -1.096719
>>> 2599 -0.5717533 -1.0657247
>>> 2795 0.0918363 0.40186396
>>> 4063 1.7279608 1.7058834
>>> 4703 0.48772874 0.8151548
>>> 3092 1.0007716 1.3466129
>>> 4904 0.7123427 0.8755629
>>> 4636 0.31645447 0.23409867
>>> 4028 1.3167495 0.77388227
>>> 2625 -0.95792514 -1.010346
>>> 89 0.4374601 0.3452794
>>> 2446 -0.15745026 -0.0731129
>>> 113 -0.6479383 -0.5333678
>>> 1235 0.39691412 0.3655415
>>> 3476 -0.7432795 -0.5654634
>>> 2936 0.18682653 0.4009084
>>> 191 -0.6031506 -0.7499491
>>> 3839 0.19065048 0.005139308
>>> 2341 -0.49323034 -0.7146312
>>> 2945 -1.5404946 -1.4307641
>>> 16 -1.481951 -1.6756974
>>> 5053 -1.5997279 -1.281742
>>> 3295 -0.7824881 -1.1979427
>>> 4344 -0.17594704 0.26201153
>>> 3261 -0.43556464 -0.4248949
>>> 3463 1.00464 -0.09113366
>>> 1760 -0.8717825 -0.76405925
>>> 4166 0.8144187 0.54515684
>>> 2747 -0.88440424 -0.44567102
>>> 4254 0.9611274 0.7756716
>>> 1557 0.28128636 0.44897342
>>> 2159 2.4096243 1.8367227
>>> 1755 -0.25129682 -0.18412185
>>> 3178 0.34251603 0.5276843
>>> 1871 0.7388451 0.3781389
>>> 1759 -0.70780104 -0.77259177
>>> 4867 -1.4370874 -1.0116079
>>> 3486 -0.16106483 -0.34880078
>>> 1312 -0.91509414 -0.8009766
>>> 2425 1.5198538 -0.026937809
>>> 2999 -0.96374947 -0.68777287
>>> 4050 -1.2514888 -1.2843934
>>> 672 0.5731096 -0.11782576
>>> 3310 0.5672021 0.3154992
>>> 4462 2.8452923 3.0536754
>>> 3034 -0.8160722 -0.79348874
>>> 4610 2.1884248 2.163767
>>> 1248 -0.82479984 -0.8382565
>>> 1794 1.133099 1.2865818
>>> 4947 -1.2046875 -1.4371197
>>> 2213 1.1214687 1.3110536
>>> 2654 0.660169 0.25807998
>>> 1662 -0.7343415 -0.55093884
>>> 1128 -1.3053776 -1.0915824
>>> 3200 -0.8356322 -1.0507003
>>> 5236 0.5745594 0.5158196
>>> 3918 0.38709608 0.5350936
>>> 2289 1.2945144 0.8050038
>>> 845 0.3371095 0.8276823
>>> 3655 0.29316455 0.13275999
>>> 2010 -0.14096348 0.20771632
>>> 3940 -1.4787211 -1.0644215
>>> 3078 -1.6118894 -1.8733852
>>> 4994 0.43318433 0.67922467
>>> 1427 1.3787518 0.9976203
>>> 2270 -0.53172576 -0.40378076
>>> 4645 0.8876004 0.8861902
>>> 1105 0.6337734 0.12409185
>>> 361 -0.7956073 -0.7173804
>>> 892 0.5586905 0.5834884
>>> 2574 1.2210029 0.07207805
>>> 4541 1.0764499 0.9533886
>>> 1061 -0.41127494 -0.12974437
>>> 4576 0.7761711 0.5664453
>>> 4736 -1.2621337 -1.5087634
>>> 4721 1.0016744 0.7754188
>>> 14 0.32229695 0.55787987
>>> 2666 1.4857376 1.1280718
>>> 1543 -1.2251798 -1.3071771
>>> 1378 -0.94246113 -0.642602
>>> 3622 0.3639305 0.1531168
>>> 3539 -0.73182577 -0.51432663
>>> 3084 0.17540514 0.1993801
>>> 3230 0.47859722 0.23197548
>>> 464 -0.72558933 -0.5123406
>>> 3358 0.80648726 0.8941621
>>> 4501 0.7480878 0.8442131
>>> 2490 0.02491854 -0.32944453
>>> 4550 -0.60981584 -0.19571716
>>> 4725 0.23812722 0.3623589
>>> 609 -1.3097639 -1.2939113
>>> 2637 -0.31165734 -0.41136578
>>> 133 -1.1240059 -0.9649076
>>> 4097 1.120926 0.6590651

Mean MAE across splits 2.7001601512232543 +- 0.0
delta MAE: 6.60e-08
