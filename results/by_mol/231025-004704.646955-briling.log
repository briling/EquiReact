namespace(experiment_name='final-cv', wandb_name='cv10-LP-proparg-xtb-noH-ns64-nv16-d16-layers3-vector-diff-node-crossattention', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=50, n_s=64, n_v=16, n_conv_layers=3, distance_emb_dim=16, radius=5.0, dropout_p=0.1, attention='cross', sum_mode='node', graph_mode='vector', dataset='proparg', combine_mode='diff', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=0.0)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-proparg-xtb/230930-001530.203006-briling.best_checkpoint.pt', CV=1, num_epochs=150, seed=123, verbose=False, process=False, subset=None, max_neighbors=50, n_s=64, n_v=16, n_conv_layers=3, distance_emb_dim=16, radius=5.0, dropout_p=0.1, attention='cross', sum_mode='node', graph_mode='vector', dataset='proparg', combine_mode='diff', atom_mapping=False, rxnmapper=False, random_baseline=False, two_layers_atom_diff=False, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=0.0, eval_on_test_split=True)

Running on device cuda:0
Loading data into memory...
dataset_prefix='data_fixarom_smiles.xtb.noH'
Coords and graphs successfully read from data/proparg/processed//
Data stdev 2.1798

CV iter 1/1
Using random splits
total / train / test / val: 753 678 38 37
trainable params in model:  4312582
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-proparg-xtb/230930-001530.203006-briling.best_checkpoint.pt
num epochs: 150
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 0.0
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 2.1798295067663513
Statistics on val_best_checkpoint
mae: 0.39471383143445665
MSELoss: 0.09808531068265439
mean_pred: -0.0666982501745224
std_pred: 0.973287308216095
mean_targets: -0.030800524353981017
std_targets: 1.106097400188446
Evaluating on test, with test size:  38
Statistics on test_split_1
mae: 0.4534992609993498
MSELoss: 0.1878394478932023
mean_pred: 0.27417649924755094
std_pred: 1.188114833831787
mean_targets: 0.26718281507492064
std_targets: 1.1969885110855103
>>> 465 0.7463919 0.043091614
>>> 530 2.6719604 2.0577233
>>> 305 -0.5075737 -0.65450275
>>> 434 -1.307567 -1.1147528
>>> 537 0.10300043 0.09278593
>>> 357 -0.97104585 -0.86596584
>>> 186 1.6552004 1.5433637
>>> 555 2.1506262 1.7314011
>>> 129 -1.3447022 -1.1863984
>>> 359 -0.03690482 2.3588982
>>> 244 -1.3343389 -1.3329897
>>> 255 -0.42121246 -0.5407171
>>> 390 0.6709697 0.4869384
>>> 154 -1.4549569 -1.3118939
>>> 371 -0.5317549 -0.49501553
>>> 751 0.79101187 0.81617856
>>> 582 0.6542732 0.590474
>>> 712 1.9076631 1.8389586
>>> 158 -0.28303444 -0.30374914
>>> 708 0.044274773 -0.051523224
>>> 271 -0.038919915 0.10296538
>>> 484 -0.9670157 -0.8773688
>>> 146 0.13639346 0.267555
>>> 394 1.6649879 1.4368715
>>> 418 -0.43359092 -0.36023617
>>> 576 1.9534346 1.8674239
>>> 744 -1.3280058 -1.4049858
>>> 680 -0.5464363 -0.4462252
>>> 588 -0.04064714 -0.14959043
>>> 290 1.3972679 1.5055057
>>> 411 0.46370268 0.28369588
>>> 630 1.5748843 1.6262349
>>> 213 0.024411682 0.28814322
>>> 358 1.8152565 1.5687376
>>> 180 -1.1630558 -1.127252
>>> 380 1.4571451 1.4624963
>>> 99 -1.285113 -1.1800678
>>> 135 1.8880879 1.5476243

Mean MAE across splits 0.4534992609993498 +- 0.0
delta MAE: 3.57e-08
