namespace(experiment_name='final-cv', wandb_name='cv10-LP-cyclo-xtb-noH-ns64-nv48-d48-layers3-energy-mlp-both-rxnmapper', device='cuda', logdir='/scratch/izar/briling/cv', checkpoint=None, CV=1, num_epochs=512, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=True, random_baseline=False, two_layers_atom_diff=True, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=0.0001)

namespace(experiment_name=None, wandb_name=None, device='cuda', logdir='logs/evaluation', checkpoint='/home/briling/scratch/cv/final-cv-cyclo-xtb/231005-005504.198476-briling.best_checkpoint.pt', CV=1, num_epochs=35, seed=123, verbose=False, process=False, subset=None, max_neighbors=10, n_s=64, n_v=48, n_conv_layers=3, distance_emb_dim=48, radius=2.5, dropout_p=0.05, attention=None, sum_mode='both', graph_mode='energy', dataset='cyclo', combine_mode='mlp', atom_mapping=True, rxnmapper=True, random_baseline=False, two_layers_atom_diff=True, noH=True, reverse=False, split_complexes=False, xtb=True, semiempirical=False, lr=0.0005, weight_decay=0.0001, eval_on_test_split=True)

Running on device cuda:0
dataset_prefix='cyclo.rxn_smiles_rxnmapper.noH.xtb.v6'
Loading data into memory...
Coords and graphs successfully read from data/cyclo/processed//
Data stdev 9.2056

CV iter 1/1
Using random splits
total / train / test / val: 4774 4297 239 238
trainable params in model:  10383318
Log directory: logs/evaluation
checkpoint: /home/briling/scratch/cv/final-cv-cyclo-xtb/231005-005504.198476-briling.best_checkpoint.pt
num epochs: 35
eval_per_epochs: 0
patience: 150
minimum_epochs: 0
models_to_save: []
clip_grad: 100
log_iterations: 100
lr: 0.0005
weight decay: 0.0001
lr scheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
factor: 0.6
min_lr: 8e-06
mode: max
lr_scheduler_patience: 60
lr_verbose: True
In trainer, metrics is {'mae': MAE()} and std is 9.205589010570657
Statistics on val_best_checkpoint
mae: 3.145076135837439
MSELoss: 0.2108393907546997
mean_pred: -0.029887957498431206
std_pred: 0.8167961825927098
mean_targets: -0.018896354362368584
std_targets: 0.936119427283605
Evaluating on test, with test size:  239
Statistics on test_split_1
mae: 3.215508780694363
MSELoss: 0.20246357433497905
mean_pred: 0.009786385794480641
std_pred: 0.8887315670649211
mean_targets: 0.03807484780748685
std_targets: 1.0444153835376104
>>> 1873 -0.804314 -0.64447755
>>> 3891 0.5844579 0.39270267
>>> 389 -0.7753813 -0.46719456
>>> 1734 -1.0032009 -0.76404214
>>> 3741 0.440619 0.6680188
>>> 762 -0.5636414 -0.3729372
>>> 3708 0.16183676 0.37346628
>>> 1406 -0.96252686 -0.9742701
>>> 2884 -1.0465598 -1.0869162
>>> 329 -0.20168936 -1.1623011
>>> 2397 3.243885 2.872502
>>> 4317 -1.0641034 -1.1453764
>>> 3753 0.048048876 0.001808025
>>> 4118 -0.91082746 -0.6800537
>>> 34 -1.3283527 -1.3738762
>>> 3348 -0.63610536 -0.660687
>>> 821 -1.0399052 -0.60232735
>>> 1438 1.1579788 1.2702912
>>> 287 0.5642161 0.66506517
>>> 2414 0.96883076 0.32440284
>>> 4731 1.4760131 1.7873042
>>> 3943 -0.4632675 -0.2169303
>>> 4413 -0.6153543 -0.79752314
>>> 2161 2.7869306 2.0282586
>>> 2040 1.2396694 1.920906
>>> 1656 -2.092463 -1.0936191
>>> 4102 -0.9908664 -0.99274385
>>> 2989 -0.015770208 0.4855175
>>> 581 -0.76243174 -0.7416103
>>> 1104 -0.62488604 0.054271843
>>> 2080 2.2162127 1.7159739
>>> 2412 0.20095208 -0.353185
>>> 1439 1.7077768 1.325289
>>> 1684 -0.21150896 -0.26070964
>>> 2240 1.0845501 0.97654927
>>> 1558 -1.0452496 -0.7528955
>>> 4277 2.5911071 2.6375897
>>> 4310 -0.23622583 -0.6962617
>>> 2533 -0.8236275 0.033265524
>>> 1146 0.47433674 0.3297678
>>> 2856 -0.5063084 -0.706816
>>> 416 -0.8424915 -0.72192574
>>> 3796 -0.49416366 0.14062946
>>> 1602 -0.00540107 0.24829839
>>> 3356 0.28803214 0.7929091
>>> 3458 1.517466 1.1351095
>>> 2478 1.3284727 0.7303817
>>> 2495 0.3790082 0.1139815
>>> 3518 -0.5543066 -0.7112921
>>> 4589 1.201527 1.2880013
>>> 3866 -0.8928671 -0.17024596
>>> 60 -0.8041529 -0.65652573
>>> 2255 -0.55653214 -0.26626012
>>> 788 -0.6885363 -0.30183068
>>> 1118 -0.6767394 -0.6380892
>>> 1792 -0.24646327 -0.5403029
>>> 4104 -0.36181694 -0.40143406
>>> 713 1.3276731 1.108007
>>> 3561 1.1067414 0.8200896
>>> 4410 -1.4161736 -0.6922373
>>> 4372 0.93627024 1.6089814
>>> 3727 -0.1570477 -0.16688503
>>> 2301 -0.3885044 -0.2724382
>>> 4557 -1.1161851 -0.6422973
>>> 3881 3.6827636 1.9017892
>>> 936 -1.1071701 -0.96939194
>>> 455 -0.8120595 -0.38646632
>>> 538 0.874878 0.185741
>>> 874 0.6014724 0.27411464
>>> 268 -0.8192963 -1.0407672
>>> 3815 -1.5794114 -1.7319043
>>> 545 -0.5305388 -0.6911708
>>> 2388 0.8287904 1.193873
>>> 4701 1.1278222 1.7805645
>>> 1551 -0.24893416 -0.29199216
>>> 1258 -0.9594762 -0.63150764
>>> 413 -0.6315382 -0.6005797
>>> 4489 0.060007297 -0.71742064
>>> 4011 -0.548491 -0.4779029
>>> 3556 0.2860971 0.26285607
>>> 3527 -0.6803107 -0.3414244
>>> 93 -1.51474 -1.8131673
>>> 1524 -0.5053028 -0.07726313
>>> 1007 -0.8441268 -0.42344472
>>> 2359 0.16999826 0.3259946
>>> 2023 0.09211625 0.5034588
>>> 2566 1.6088505 0.21738482
>>> 126 -1.0538303 -1.3695939
>>> 2201 -1.2115248 -0.94238883
>>> 443 1.5913395 1.1584774
>>> 4477 -0.6345279 -0.6409306
>>> 3132 0.02297899 0.6002859
>>> 2578 2.163856 0.40709513
>>> 3095 0.8313305 0.56152385
>>> 3860 -0.99577105 -0.7765327
>>> 4321 -0.5251936 -0.058639806
>>> 3072 0.2771404 -0.11747958
>>> 3656 1.0584921 0.6287806
>>> 1649 -1.1788175 -0.5581416
>>> 2483 -0.48046637 0.100777715
>>> 2227 0.4091365 0.6444897
>>> 1647 -1.4550912 -1.3953564
>>> 434 -1.0769453 -0.9004151
>>> 508 0.71550345 0.23110425
>>> 4030 -0.9724724 -0.719741
>>> 32 -1.0144738 -1.0106643
>>> 2378 1.2554752 0.99564236
>>> 2072 -0.29621848 0.37815285
>>> 4295 -1.2732406 -0.94270384
>>> 2880 -0.84800845 -1.4740771
>>> 3895 0.21886146 0.048946094
>>> 3367 -0.6830394 -0.42253804
>>> 2819 0.9916661 0.8631134
>>> 180 -0.6034696 -0.66560227
>>> 2871 -0.02298058 -0.24904548
>>> 1282 -0.13555674 -0.3241385
>>> 4726 3.3202038 2.4982774
>>> 2046 -0.3958796 -0.89050657
>>> 4360 -0.20757169 -0.22873735
>>> 2174 -0.8792157 -0.8057519
>>> 4391 -0.92508626 -0.4501903
>>> 719 0.05733386 -0.14498127
>>> 3892 0.99644536 0.48286813
>>> 295 0.9211319 0.77617955
>>> 3963 0.2800864 0.07303412
>>> 794 -0.72247225 -0.81858
>>> 3665 -1.074838 -0.4852949
>>> 4201 1.6159328 1.117435
>>> 3143 0.051522993 0.38467562
>>> 3306 -0.6112049 -0.18910532
>>> 2395 -1.1038252 -0.54304844
>>> 922 -0.41235054 -1.4217659
>>> 4007 0.023495713 -0.45624295
>>> 2467 -1.4061968 -1.3451259
>>> 2557 0.84699005 0.8281619
>>> 3121 -0.81999934 0.085693926
>>> 1326 0.29189464 -0.10974361
>>> 4542 2.3729944 1.8645393
>>> 3273 -1.0975051 -1.1109138
>>> 915 -1.7742411 -1.1330502
>>> 1425 1.2771043 0.9717601
>>> 231 -0.001554758 0.19733071
>>> 2778 -0.15709233 -0.37884703
>>> 1474 0.5618798 -0.04431611
>>> 1221 0.4606435 0.4013998
>>> 2751 -0.4219523 -0.078736946
>>> 2917 0.36709163 0.69320893
>>> 1100 -0.36901727 -0.40186128
>>> 1257 -0.40747365 -0.16726024
>>> 1888 0.41414487 1.1967217
>>> 1922 -0.011388625 0.09647733
>>> 687 -0.6026876 -1.2065651
>>> 4610 -1.4597112 -1.459189
>>> 2599 -0.7272424 -0.8212297
>>> 2795 -0.29068187 -0.051656663
>>> 4063 1.4626462 0.9653513
>>> 3092 1.1195902 1.0521184
>>> 4028 1.6125013 0.88241
>>> 2625 1.2405812 1.4649776
>>> 89 0.5569525 0.3708114
>>> 2446 0.71012634 0.3559041
>>> 113 -1.1779362 -0.8141195
>>> 1235 -1.0765408 -1.0344993
>>> 3476 -0.1699354 -0.4675744
>>> 2936 -0.046598837 0.090016566
>>> 191 -1.0875645 -1.059094
>>> 3839 -1.6475681 -1.8942205
>>> 2341 1.0695937 0.53276724
>>> 2945 -0.057609595 -0.51858836
>>> 16 -1.534198 -1.8395301
>>> 4576 3.9572244 3.1785893
>>> 3295 -0.20201539 -0.38175076
>>> 4344 0.8414983 0.08939413
>>> 3261 -0.38751996 -0.5785021
>>> 3463 0.50136656 0.0975925
>>> 1760 -0.41102144 -0.599372
>>> 4166 -0.2991508 -0.4472741
>>> 2747 2.3169615 2.164376
>>> 4254 -0.8023183 -0.51658136
>>> 1557 -0.27081808 -0.80122125
>>> 2159 2.4671519 2.1652496
>>> 1755 -0.2257704 -0.3009664
>>> 3178 0.34864894 -0.22069447
>>> 1871 -0.7672431 -0.68612146
>>> 1759 -0.46570793 -0.13077486
>>> 3486 0.5275994 0.24591795
>>> 1312 -0.6152286 -0.091369
>>> 2425 -0.8782206 -0.7754672
>>> 2999 0.842043 0.4966283
>>> 4050 1.3270625 1.160122
>>> 672 1.2893723 0.36704108
>>> 3310 -0.41426003 -0.4047154
>>> 4462 1.2846575 1.2122257
>>> 3034 -0.11991107 -0.14398794
>>> 1248 -0.5823968 -0.2258036
>>> 1794 -1.3655338 -1.0359266
>>> 2213 0.9052141 1.0396024
>>> 2654 0.5142607 0.22863646
>>> 1662 0.63029563 -0.17084567
>>> 1128 0.5356618 0.82764274
>>> 3200 1.197928 0.74331194
>>> 4747 -0.6134806 -0.5728213
>>> 3918 1.4647708 0.5295657
>>> 2289 -0.73930174 -0.55000407
>>> 845 0.22633392 1.0960228
>>> 3655 0.9034063 0.6931081
>>> 2010 -0.13900235 0.01436533
>>> 3940 -0.7778068 -0.17874719
>>> 3078 0.36089557 -0.16035323
>>> 4525 0.506575 1.2181937
>>> 1427 1.403242 1.475464
>>> 2270 -0.07931965 0.58731025
>>> 1105 -0.6805163 -0.92670876
>>> 361 -0.16465278 0.064489424
>>> 892 1.4800932 0.59880066
>>> 2574 -0.6513742 -0.43971816
>>> 1061 -0.42918256 0.00703799
>>> 14 0.3766624 0.27270377
>>> 2666 -1.1571989 -0.68408823
>>> 1543 1.1789078 0.46634975
>>> 1378 -0.045034282 0.69329166
>>> 3622 1.7089394 1.1296452
>>> 3539 -0.7119147 -0.3331222
>>> 3084 -0.56938964 -0.04723192
>>> 3230 0.86108834 0.63947225
>>> 464 0.7673291 0.006219182
>>> 3358 0.012351639 -0.07306641
>>> 4501 -1.6101024 -0.8857171
>>> 2490 0.80881894 0.9438042
>>> 609 -1.3579831 -0.7121985
>>> 2637 1.1453823 0.7971538
>>> 133 1.0549593 0.54890925
>>> 4097 -0.56959474 -0.34017026
>>> 293 -1.3388032 -1.1254327
>>> 3101 0.62499917 0.52992666
>>> 3406 0.0786676 -0.1246279
>>> 3573 0.38165322 0.51518965
>>> 3155 1.1103164 1.096961
>>> 881 -0.9533992 -1.4344939

Mean MAE across splits 3.215508780694363 +- 0.0
delta MAE: 1.83e-08
